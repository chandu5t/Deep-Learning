{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "2vtaxHsL_RjY",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the dataset\n",
        "dataframe = pd.read_csv('/content/tesla.csv')  # Ensure the dataset has 'Date' and 'Close' columns\n",
        "dataframe['Date'] = pd.to_datetime(dataframe['Date'])\n",
        "dataframe.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "EmUWnfaMAdc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Preprocess the data (Normalization)\n",
        "closing_prices = dataframe[['Close']].values\n",
        "scaler_obj = MinMaxScaler(feature_range=(0, 1))\n",
        "normalized_data = scaler_obj.fit_transform(closing_prices)"
      ],
      "metadata": {
        "id": "NP-CoLNHBQV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Create sequences for the RNN\n",
        "def generate_sequences(data, seq_len):\n",
        "    X_seq, y_seq = [], []\n",
        "    for idx in range(len(data) - seq_len):\n",
        "        X_seq.append(data[idx:idx + seq_len])\n",
        "        y_seq.append(data[idx + seq_len])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "sequence_len = 60  # You can modify the sequence length as needed\n",
        "X_features, y_labels = generate_sequences(normalized_data, sequence_len)"
      ],
      "metadata": {
        "id": "F5eZq4qIBQsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Split the data into train and test sets\n",
        "train_test_split_idx = int(len(X_features) * 0.8)\n",
        "X_train_data, y_train_data = X_features[:train_test_split_idx], y_labels[:train_test_split_idx]\n",
        "X_test_data, y_test_data = X_features[train_test_split_idx:], y_labels[train_test_split_idx:]"
      ],
      "metadata": {
        "id": "RuBWaukCBQ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6: Build the RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(SimpleRNN(units=50, activation='relu', input_shape=(sequence_len, 1)))\n",
        "rnn_model.add(Dense(1))  # Output layer for predicting the stock price\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e-KuYe6BYhC",
        "outputId": "a19dbdd9-f266-4c3f-f406-e84539466882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Train the model\n",
        "training_history = rnn_model.fit(X_train_data, y_train_data, epochs=10, batch_size=32, validation_data=(X_test_data, y_test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ89YsiVBbOR",
        "outputId": "d5086b03-9cc2-4c24-db97-f86a7c22b940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0388 - val_loss: 6.8694e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.1638e-05 - val_loss: 5.3278e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.2950e-05 - val_loss: 5.1888e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.9990e-05 - val_loss: 5.0271e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.8378e-05 - val_loss: 5.3007e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.7127e-05 - val_loss: 5.2913e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9941e-05 - val_loss: 5.8742e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.7196e-05 - val_loss: 5.0228e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.4383e-05 - val_loss: 5.7959e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.6043e-05 - val_loss: 5.0416e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8: Predict for the next 20 days\n",
        "future_predictions = []\n",
        "recent_sequence = normalized_data[train_test_split_idx - sequence_len:train_test_split_idx]\n",
        "\n",
        "for _ in range(20):  # Predict for the next 20 days\n",
        "    recent_sequence = np.reshape(recent_sequence, (1, sequence_len, 1))  # Ensure correct shape for RNN\n",
        "    predicted_price = rnn_model.predict(recent_sequence)\n",
        "\n",
        "    future_predictions.append(predicted_price[0][0])  # Store predicted price\n",
        "\n",
        "    # Reshape predicted price and append it to the sequence\n",
        "    predicted_price = np.reshape(predicted_price, (1, 1, 1))\n",
        "    recent_sequence = np.append(recent_sequence[:, 1:, :], predicted_price, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hU1wsbpBdBT",
        "outputId": "816109a8-768e-4e68-bb8e-af96a7f0d05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_future_prices = scaler_obj.inverse_transform(np.array(future_predictions).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "x_t_hJE3Bf7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_future_prices = scaler_obj.inverse_transform(normalized_data[train_test_split_idx:train_test_split_idx+20])"
      ],
      "metadata": {
        "id": "Y46pFpQKBhsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for day in range(20):\n",
        "    print(f\"Day {day+1}: Actual: {actual_future_prices[day][0]}, Predicted: {predicted_future_prices[day][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bqWmCX6BjZ5",
        "outputId": "3b9d0fbb-09e6-40f6-ae62-c828475e5147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day 1: Actual: 328.980011, Predicted: 337.7732238769531\n",
            "Day 2: Actual: 331.660004, Predicted: 338.8116149902344\n",
            "Day 3: Actual: 325.200012, Predicted: 339.422119140625\n",
            "Day 4: Actual: 317.290009, Predicted: 340.16229248046875\n",
            "Day 5: Actual: 311.640015, Predicted: 341.677734375\n",
            "Day 6: Actual: 315.359985, Predicted: 343.0973205566406\n",
            "Day 7: Actual: 311.350006, Predicted: 344.391357421875\n",
            "Day 8: Actual: 320.529999, Predicted: 345.69891357421875\n",
            "Day 9: Actual: 317.25, Predicted: 346.9515686035156\n",
            "Day 10: Actual: 314.619995, Predicted: 348.15130615234375\n",
            "Day 11: Actual: 316.579987, Predicted: 349.32159423828125\n",
            "Day 12: Actual: 336.410004, Predicted: 350.4683837890625\n",
            "Day 13: Actual: 333.690002, Predicted: 351.5943298339844\n",
            "Day 14: Actual: 334.799988, Predicted: 352.7065734863281\n",
            "Day 15: Actual: 337.950012, Predicted: 353.8046569824219\n",
            "Day 16: Actual: 336.220001, Predicted: 354.8880615234375\n",
            "Day 17: Actual: 340.059998, Predicted: 355.9576416015625\n",
            "Day 18: Actual: 347.160004, Predicted: 357.0140380859375\n",
            "Day 19: Actual: 344.570007, Predicted: 358.0567626953125\n",
            "Day 20: Actual: 350.019989, Predicted: 359.0856628417969\n"
          ]
        }
      ]
    }
  ]
}